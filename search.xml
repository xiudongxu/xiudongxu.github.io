<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2019%2F07%2F16%2F2%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[JAVA锁相关]]></title>
    <url>%2F2018%2F11%2F21%2FJAVA%E9%94%81%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[synchronized使用及原理解析](https://www.cnblogs.com/little-sheep/p/9909111.html) 深入理解Java并发之synchronized实现原理 自己动手写把锁 Object.wait()/notify() https://www.jianshu.com/p/34b61d3cd227 无竞争情况下 使用偏向锁消除整个同步，减少同一个线程获取锁的代价。这个锁会一直偏向于第一个获得它的线程，如果接下该锁没有被其他线程获取，则持有偏向锁的线程将永远不需要再进行同步。 无锁相关： 一般都是用cas 来实现无锁 java ConcurrentLinkedQueue 就是无锁队列 并发队列分为 阻塞队列和非阻塞队列 阻塞队列有 ArrayBlockingQueue LinkedBlockingQueue PriorityBlockingQueue SynchronousQueue 等 非阻塞队列有 ConcurrentLinkedQueue]]></content>
      <categories>
        <category>java学习</category>
      </categories>
      <tags>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库相关总结]]></title>
    <url>%2F2018%2F11%2F15%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Innodb ](http://blog.itpub.net/7728585/viewspace-2146183/) 数据库的隔离级别以及悲观锁和乐观锁详解 Innodb中的事务隔离级别实现原理 mysql innodb如何在RR级别下防止幻读 mysql有一个autocommit参数，默认是on，他的作用是每一条单独的查询都是一个事务，并且自动开始，自动提交（执行完以后就自动结束了，如果你要适用select for update，而不手动调用 start transaction，这个for update的行锁机制等于没用，因为行锁在自动提交后就释放了），所以事务隔离级别和锁机制即使你不显式调用start transaction，这种机制在单独的一条查询语句中也是适用的，分析锁的运作的时候一定要注意这一点。 mysql 有一种发生死锁的情况 和 解决办法， 掘金上也有文章 挖坑的张师傅 如果用到了非主键索引，msyql会先锁定非主键索引，再锁定主键索引。 如果两条sql执行间隔时间非常短的话，会出现资源争夺的情况，可能死锁， 做update的话，（并发量高的情况？）先把update的数据先条件查询出来，再做主键id的更新]]></content>
      <categories>
        <category>DB-Mysql</category>
      </categories>
      <tags>
        <tag>锁和隔离级别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty源码解析]]></title>
    <url>%2F2018%2F11%2F10%2FNetty%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[NIO相关](https://www.cnblogs.com/java-zhao/p/9195943.html) netty的高性能体现在哪里： 1.多路复用通信 2.异步IO 3.零拷贝 4.内存池 5.高效的Reactor线程模型 单线程，多线程，主从Reactor多线程模型 直接缓冲区是另外一种 ByteBuf 模式。我们期望用于对象创建的内存分配永远都来自于堆 中，但这并不是必须的——NIO 在 JDK 1.4 中引入的 ByteBuffer 类允许 JVM 实现通过本地调 用来分配内存。这主要是为了避免在每次调用本地 I/O 操作之前（或者之后）将缓冲区的内容复 制到一个中间缓冲区（或者从中间缓冲区把内容复制到缓冲区）。 ByteBuffer的Javadoc 明确指出：“直接缓冲区的内容将驻留在常规的会被垃圾回收的堆 之外。”这也就解释了为何直接缓冲区对于网络数据传输是理想的选择。如果你的数据包含在一 个在堆上分配的缓冲区中，那么事实上，在通过套接字发送它之前，JVM将会在内部把你的缓冲 区复制到一个直接缓冲区中。 直接缓冲区的主要缺点是，相对于基于堆的缓冲区，它们的分配和释放都较为昂贵。如果你 正在处理遗留代码，你也可能会遇到另外一个缺点：因为数据不是在堆上，所以你不得不进行一 次复制 慕课网Netty课程学习笔记 2-2 服务端监听端口 NioEventLoop 一个连接 ：io 编程模型是 socket，nio 编程模型是 channel 业务逻辑处理是由pipeline将各个处理业务的channelHandler串联起来的 2-3 netty组件介绍 NioEventLoop 对应 java 的Thread 本质上就是启动两种线程 它同时做两个事情 接收连接 处理业务。 run方法里面的select 就是server端接收连接的操作 和 client端拿到数据流的操作。 具体后面分析。 接收到连接后 调用 processSelectedKeys() 处理对应每一个连接 Channel 对应java的Socket 它对java socket的封装 processSelectedKeys 里面的 unsafe.read() 对应两个实现类 一个是 NioByteUnsafe 是client端的数据流读写。 NioMessageUnsafe 对应的是 server端接收连接的 -&gt; doReadMessage(readbuffer) -&gt;NioServerSocketChannel 里面能看到对应java底层的 socketChannel 就是 java 的 ServerSocketChannel 把这个封装成 netty 里面的 NioSocketChannel 最后基于 这个nsc 进行数据的读取的写入 ByteBuffer 对应数据的读写 Pipeline -&gt; Logic Chine 什么时候把pipeline 加入到每个channel 的处理过程的？ 在NioSocketChannel 的构造方法中可以找到答案。 每一个channle 都会有一个pipeline 然后把 逻辑链路 加到channel 里面 channel 每一次 对数据流的读写 都会经过pipeline ChannelHandler -&gt; Logic 逻辑处理块 ChannelHandler 是 加在 pipeline 里面的 3-2 netty 服务端启动 问题1：服务端的socket在哪里初始化。 问题2：在哪里accept连接。 总共分4步： 1.创建服务端channel 2.初始化服务端channel 3.注册selector 把jdk 的底层的channel注册到selector上 并把 NioServerSocketChannel attach 到 jdk的channel上 这样后续 selector 出事件之后 就能 拿到attachement 就能拿到 netty 封装的channel 4.端口绑定 调用 jdk 底层的绑定API 1.1 bind() [用户代码入口] ​ initAndRegister()[初始化并注册] ​ newChannel()[创建服务端channel] 创建服务端channel 就是调用 bootStrap.channel(NioServerSocketChannel); 这个类进行反射 也就是要看构造函数 反射创建服务端Channel（这里思考为什么要用反射？ 因为你要提供给别人去用 别人传的类可能不同 new 相当于提前写死了要创建的类 就不能动态加载了） new Socket[通过 jkd来创建底层jdk channel] NioServerSocketChannelConfig()[tcp参数配置类] AbstractNioChannel() ​ configureBlocking(false)[阻塞模式] ​ AbstractChannel()[创建id,unsafe,pipeline] 2.1 接着上面 1.1 的 newChannel 后面 init() 初始化服务端channel init()[初始化入口] 保存用户自定义的属性，创建一个连接接入器 就是把这些东西都给赋值上去 ​ set ChannleOptions,ChannelAttrs ​ set ChildOptions,ChildAttrs 【每次新创建一个连接 都会把这两个属性配置上去】 ​ config handler [配置服务端pipeline] ​ add ServerBootstrapAcceptor[特殊的处理器 把accept到的连接 分配一个Nio线程] 3.1 注册selector initAndRegister 调用到 config().group().register(channel); AbstractChannel register()[入口] ​ this.eventLoop = eventLoop[绑定线程] ​ register0()[实际注册] ​ doRegister()[调用jdk底层注册] ​ invokerHandlerAddedIfNeeded(); 触发回调 ​ fireChannelRegister()[传播事件:把注册成功传递到用户代码里面去] 4.1 AbstractUnsafe.bind()[入口] ​ doBind() ​ javaChannel().bind()[jdk底层绑定] ​ pipeline.fireChannelActive()[传播事件] ​ HeadContext.readIfIsAutoRead(); 将之前注册到select上的事件 重新绑定为一个 accept事件 4.1 NioEventLoop概述 问题三个： 1.默认情况下，Netty服务端起多少线程？何时启动？ 2.Netty 是如何解决jdk空轮训bug？ 3.Netty 是如何保证异步串行无锁化？ NioEventLoop创建、启动、执行逻辑。 4.2 NioEventLoop创建 -&gt; MultithreadEventExecutorGroup newNioEventLoopGroup[线程组，默认2*cpu] ​ new ThreadPerTaskExecutor()[线程创建器] ​ for(){newChild()}[构造NioEventLoop] ​ chooserFactory.newChooser()[线程选择器] 123public NioEventLoopGroup(int nThreads, Executor executor)&#123; this(nThreads, executor, SelectorProvider.provider());&#125; 4.3 ThreadPerTaskExecutor 线程执行器 每次执行任务都会创建一个线程实体 NioEventLoop线程命名规则nioEventLoop-1-xx -1 指的是第几个nioEventLoopGoup -xx 指的是第几个nioEventLoop 重点：netty 底层的thread 不是java 原生的thread 而是经过包装的FastTreadLocalThread(threadGroup , r , name); 4.4 创建NioEventLoop线程 newchild() 保存线程执行器ThreadPerTaskExecutor 创建一个MpscQueue 创建一个selector 一个selector 和 一个nioEventLoop 做绑定 来到 NioEventLoop 构造函数的父类构造函数 taskQueue = newTaskQueue return PlatformDependent.newMpscQueue(maxPendingTasks); new Mulity Producer Single Consumer Queue 4.5 chooserFactory.newChooser(); 创建chooser 给新连接绑定对应的EventLoop 对应的就是 MultithreadEventExecutorGroup 的 next 方法。 调用chooser.next(); 对应一个NioEventLoop[] 数组 从头开始绑定 一个连接对应一个 超出就从头再来。 创建chooser chooserFactory.newChooser(); isPowerOfTwo()[判断是否是2的幂 如 2、4、8、16] ​ PowerOfTwoEventExecutorChooser[优化] ​ index++ &amp;( length - 1 ) ​ GenericEventExecutorChooser[普通] ​ abs(index++ % length) 4.6 NioEventLoop 启动 bind() -&gt; execute(task)[入口] ​ startThread() -&gt; doStartThread()[创建线程] ​ ThreadPerTaskExecutor.execute() 每次执行任务都会创建一个线程 ​ thread = Thread.currentThread(); 将此线程进行保存 创建fastThreadLocalThread ​ NioEventLoop.run(); 启动 问题： channel 和 eventLoop 什么关系？ 进度：2019年04月17日08:53:06 视频4-6 4.7 NioEventLoop 执行 SingleThreadEventExecutor.this.run(); NioEventLoop.run(); ​ run() -&gt; for(;;) ​ select()[检查是否有io事件] ​ processSelectedKeys()[处理io事件] ​ runAllTasks()[处理异步任务队列] 一个nioEventLoop 对应一个selector 轮训注册到这个selector上的io事件 4.8 select()方法执行逻辑 deadline以及任务穿插逻辑处理 阻塞式select 避免jdk空轮训的bug 4.8.1 select wakenUp 标记这个select 是不是唤醒状态。 NioEventLoop 底层会有一个定时任务队列（后面会讲到） 如果超时的话 会直接执行一次 非阻塞的selector.selectNow() 如果没有到超时时间的话 阻塞1s进行一个select事件 并把计数++ 如果没有阻塞 就立即返回了 这样就是空轮训 空轮训次数 大于一个阈值 512 会rebuildSelector() 方法 把老的selctor的key 注册到新的 selector上去]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>源码解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ES相关命令整理]]></title>
    <url>%2F2018%2F10%2F09%2FES%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[–查询出所有的索引 curl ‘10.32.64.16:9228/_cat/indices?v’ –查询对应索引的所有类型 curl ‘10.32.64.16:9228/mts_checkup_order/_search?q=*&amp;pretty’ –查询一个确定的文档 curl ‘10.32.64.16:9228/mts_checkup_order/orders/601049824311?pretty’ –查询映射 curl ‘10.32.64.16:9228/mts_checkup_order/_mapping’ –删除索引 curl -XDELETE ‘10.32.64.16:9228/mts_checkup_order?pretty’ –新建索引 curl -XPUT ‘10.32.64.16:9228/mts_checkup_order?pretty’ -H ‘Content-Type: application/json’ -d’{“settings”:{“number_of_shards”:1,”number_of_replicas”:1},”mappings”:{“orders”:{“dynamic_date_formats”:[“yyyy-MM-dd”,”yyyy-MM-dd HH:mm:ss”,”date_optional_time”],”dynamic_templates”:[{“strings_as_keywords”:{“match”:”*”,”match_mapping_type”:”string”,”mapping”:{“ignore_above”:255,”index”:”not_analyzed”,”type”:”keyword”,”norms”:false}}}]}}}’]]></content>
      <categories>
        <category>ES</category>
      </categories>
      <tags>
        <tag>命令总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线上问题整理]]></title>
    <url>%2F2018%2F09%2F15%2F%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[线上问题排查步骤：第一步 top free df 三连 第二步 保存线程栈现场 jstack pid &gt; jstack.log 第三步 保存堆现场 注意 : 需要先把对外服务干掉才能dump jmap -dump:format=b,file=heap.log pid 第三步 重启服务 第四步 MAT工具分析 下载dump文件 记得压缩完了 再下载。 今天遇到的一个问题：负载过高 配置2C4G 使用sar -W 开启 swap 在swap期间 gc日志 是同步写入磁盘的 所以会导致整个机器hang住 GC时间长达30S 结论：一定要关闭swap区 如何通过gc.log 看问题 ？在GC日志里面有这么一行，我们需要重点关注一下：youngGc Time[user=0.01 sys=0.01 real=0.02] user代表 应用程序 处理的时间 sys代表 除应用程序外 CPU一般切换 代表的时间 real代表 一般是user和sys的和 如果 大于的话 那就 一般是IO打住了 或者swap区什么的 vmstat 内存换入换出 netstat 网络活动 iostat 在GC过程中会使GC时间变长 一些工具记录汇总：jstat 是一个非常强大的 JVM 监控工具，一般用法是： jstat [-命令选项] [vmid] [间隔时间/毫秒] [查询次数] 它支持的查看项有： -class 查看类加载信息 -compile 编译统计信息 -gc 垃圾回收信息 -gcXXX 各区域 GC 的详细信息 如 -gcold 使用它，对定位 JVM 的内存问题很有帮助。]]></content>
      <categories>
        <category>架构相关</category>
      </categories>
      <tags>
        <tag>线上问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客迁移]]></title>
    <url>%2F2018%2F09%2F10%2F%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%2F</url>
    <content type="text"><![CDATA[已经过了好久了，之前的内容也都是一直整理在本地的文件夹中 或者 公司的WIKI上 或者 有道云上，看了同事总结的东西，还是决定重回这个blog上！ 第一个问题 如何迁移？原来这个hexo的内容都是在我家里的台式机上的，现在要迁移到我的工作笔记本上。 第一步 直接clone下载你的静态文件 注意：* 中间的内容要根据自己的内容进行替换`git clone https://github.com/yourname/name*.github.io.git` 第二步 删除所有东西 第三步 把之前维护的blog文件 全部搬到这边来 第四步 git add . 第五步 git commit -m “finish” 第六步 git push –set-upstream origin hexo 然后安装 hexo brew install node npm install -g hexo-cli npm install hexo-deployer-git –save 搞定！]]></content>
      <categories>
        <category>生活点滴</category>
      </categories>
      <tags>
        <tag>个人记录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java8流相关Stream]]></title>
    <url>%2F2018%2F07%2F24%2F%20java8%E6%B5%81%E7%9B%B8%E5%85%B3Stream%2F</url>
    <content type="text"><![CDATA[最近去了新公司，发现里面的循环什么的基本都是用stream来写的。就是java8那个流，感觉这种写法优雅，易懂，非常方便，所以在此学习并且记录下来。希望对Stream有一个大体上的认识。 简介:一个宏观上的介绍：流在管道中传输，并且可以在管道的节点上进行处理，比如筛选，排序，聚合等。元素流在管道中经过中间操作(intermediate operation)的处理，最后由最终操作(terminal operation)得到前面处理的结果。 流管道示意图: 流的操作分为两种：中间操作方法：像filter这种，返回流对象本身，最终不产生新集合的方法。最终操作方法：像count这种最终会从stream产生值的方法。 两个基础特性： Pipelining ：中间操作都会返回流对象本身。这样多个操作可以串联成一个管道，如同流式风格。这样可以对操作进行优化，比如延迟执行和短路。 内部迭代 ：以前对集合的遍历都是通过Iterator或者For-each的方式，显示的在集合外部进行迭代，这叫做外部迭代，Stream提供了内部迭代的方式，通过访问者模式实现。 为什么不在集合类实现这些操作，而是定义了全新的Stream API？Oracle官方给出了几个重要原因：一是集合类持有的所有元素都是存储在内存中的，非常巨大的集合类会占用大量的内存，而Stream的元素却是在访问的时候才被计算出来，这种“延迟计算”的特性有点类似Clojure的lazy-seq，占用内存很少。二是集合类的迭代逻辑是调用者负责，通常是for循环，而Stream的迭代是隐含在对Stream的各种操作中，例如map()。 一、创建Stream数据源流的来源。可以是集合，数组，I/O channel，产生器generator等。(Map不能作为Stream的源) 12345678910111213// 1.Individual valuesStream&lt;String&gt; s = Stream.of("a", "b", "c");// 2. ArraysString [] strArray = new String[] &#123;"a", "b", "c"&#125;;Stream&lt;String&gt; arrs = Stream.of(strArray);// 3. CollectionsList&lt;String&gt; list = Arrays.asList(strArray);Stream&lt;String&gt; lists = list.stream();// 4. iterate Stream.iterate(0, n -&gt; n + 3).limit(10).forEach(x -&gt; System.out.print(x + " ")); // 0 3 6 9 12 15 18 21 24 27// 5. generate//将一个无限的stream限制在10个"test"字符串String joinStr = Stream.generate(() -&gt; "test").limit(10).collect(Collectors.joining(",")); stream:集合创建串行流 12List&lt;String&gt; strings = Arrays.asList("abc", "", "bc", "efg", "abcd","", "jkl");List&lt;String&gt; filtered = strings.stream().filter(string -&gt; !string.isEmpty()).collect(Collectors.toList()); parallelStream:集合创建并行流 12List&lt;String&gt; strings = Arrays.asList("abc", "", "bc", "efg", "abcd","", "jkl");List&lt;String&gt; filtered = strings.parallelStream().filter(string -&gt; !string.isEmpty()).collect(Collectors.toList()); 二、中间操作distinct:去除重复123List&lt;String&gt; lists = Arrays.asList("1", "2", "3", "3", "follow","wind", "followwwind");lists.stream().distinct().forEach(p -&gt; System.out.print(p + "\t")); //lists.stream().distinct().forEach(p -&gt; System.out.print(System.out::println); filter:过滤元素，返回过滤条件通过的流。1lists.stream().filter(p -&gt; p.length() &gt; 1).forEach(p -&gt; System.out.print(p + "\t")); sorted:流排序，中间操作返回流本身。12345678910lists.stream().filter(str -&gt; str.contains("w")) .sorted((str1, str2) -&gt; &#123; if (str1.length() == str2.length()) &#123; return 0; &#125; else if (str1.length() &gt; str2.length()) &#123; return 1; &#125; else &#123; return -1; &#125; &#125;).forEach(System.out::println); limint:获取截取的前N个元素，如果原Stream中包含的元素个数小于N，那就获取其所有的元素。1lists.stream().limit(5).forEach(p -&gt; System.out.print(p + "\t")); skip:返回一个丢弃原Stream的前N个元素后剩下元素组成的新Stream。1lists.stream().skip(5).forEach(p -&gt; System.out.print(p + "\t")); peek:生成一个包含原Stream的所有元素的新Stream，同时会提供一个消费函数（Consumer实例），新Stream每个元素被消费的时候都会执行给定的消费函数。1lists.stream().peek(p -&gt; &#123;p = p.toUpperCase(); System.out.println(p);&#125;).forEach(System.out::println); map:接受lambda ,将元素转换成其他形式或提取信息。接受一个函数作为参数，该函数会被应用到每个元素上，并将其映射成一个新的元素12345678910lists.stream().map(p -&gt; p + "--&gt;").forEach(System.out::print); lists.stream().map(p -&gt; p.split("")).map(p -&gt; &#123; String tmp = ""; if(p.length &gt; 1)&#123; tmp = p[1]; &#125;else&#123; tmp = p[0]; &#125; return tmp + "\t"; &#125;).forEach(System.out::print); flatMap:和map类似，不同的是其每个元素转换得到的是Stream对象，会把子Stream中的元素压缩到父集合中1234567891011lists.stream().flatMap(p -&gt; Stream.of(p.split("www"))).forEach(p -&gt; System.out.print(p + "\t"));//看看使用flatMap和不用faltMap输出结果的异同。Stream&lt;List&lt;Integer&gt;&gt; inputStream = Stream.of( Arrays.asList(1), Arrays.asList(2, 3), Arrays.asList(4, 5, 6) ); System.out.println(); Stream&lt;Integer&gt; outputStream = inputStream. flatMap((childList) -&gt; childList.stream()); outputStream.forEach(p -&gt; System.out.print(p + "\t")); 三、最终操作forEach:每个元素匹配1lists.stream().forEach(System.out::print); match:流匹配，终结操作123System.out.println(lists.stream().allMatch(str -&gt; str.length() == 3));System.out.println(lists.stream().anyMatch(str -&gt; str.length() &gt; 5));System.out.println(lists.stream().noneMatch(str -&gt; str.length() &gt; 5)); count:1System.out.println(lists.stream().count()); reduce:可以将流中元素反复结合起来，得到一个值。可以设置一个初始值。123Optional&lt;String&gt; reOptional = lists.stream().reduce((str, str2) -&gt; str + "--&gt;" + str2);reOptional.ifPresent(System.out::println); //lists.stream().filter(p -&gt; p.matches("\\d+")).mapToInt(p -&gt; Integer.valueOf(p)).reduce(Integer::sum).ifPresent(System.out::println); collect:收集。将流转换为其他形式。接收一个Collector接口的实现，用于给Stream中元素做汇总的方法12345List&lt;String&gt; ll = lists.stream().collect(Collectors.toList());lists.stream().collect(Collectors.maxBy((p1, p2) -&gt; p1.compareTo(p2))).ifPresent(System.out::println); lists.stream().collect(Collectors.minBy((p1, p2) -&gt; p1.compareTo(p2))).ifPresent(System.out::println); int s = lists.stream().filter(p -&gt; p.matches("\\d+")).collect(Collectors.summingInt(p -&gt; Integer.valueOf(p)));String liString = lists.stream().collect(Collectors.joining(",")); sum:做求和汇总1lists.stream().filter(p -&gt; p.matches("\\d+")).mapToInt(p -&gt; Integer.valueOf(p)).sum(); findFirst:查找第一个123Optional&lt;String&gt; firstOptional = lists.stream().findFirst();firstOptional.ifPresent(System.out::println);Stream.of().findFirst().ifPresent(System.out::println); findAny:查找随机一个1lists.stream().findAny().ifPresent(System.out::println); Collectors:将流转化为集合和聚合元素。可以返回列表或者字符串123456List&lt;String&gt;strings = Arrays.asList("abc", "", "bc", "efg", "abcd","", "jkl");List&lt;String&gt; filtered = strings.stream().filter(string -&gt; !string.isEmpty()).collect(Collectors.toList()); System.out.println("筛选列表: " + filtered);String mergedString = strings.stream().filter(string -&gt; !string.isEmpty()).collect(Collectors.joining(", "));System.out.println("合并字符串: " + mergedString); summaryStatistics:统计，主要作用于int、double、long等类型上，产生各种统计结果123456List&lt;Integer&gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);IntSummaryStatistics stats = integers.stream().mapToInt((x) -&gt; x).summaryStatistics();System.out.println("列表中最大的数 : " + stats.getMax());System.out.println("列表中最小的数 : " + stats.getMin());System.out.println("所有数之和 : " + stats.getSum());System.out.println("平均数 : " + stats.getAverage()); 分区，分组，多级分组:进阶，高级，复杂操作，暂且略去。 参考文献：1.https://blog.csdn.net/dongyuancaizi/article/details/787959452.http://www.runoob.com/java/java8-streams.html3.https://blog.csdn.net/followwwind/article/details/782113954.https://www.liaoxuefeng.com/article/001411309538536a1455df20d284b81a7bfa2f91db0f223000]]></content>
      <categories>
        <category>JAVA学习</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单的性能优化总结]]></title>
    <url>%2F2018%2F05%2F21%2F%E7%AE%80%E5%8D%95%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[一、Web前端性能优化 浏览器访问优化 减少http请求，主要是合并css，合并js，合并图片，浏览器一次访问的js，css合并成一个文件，多张图片合并成一张，如果每张图片有不通的超链接，可通过css偏移响应鼠标点击操作，构造不通的URL 。 使用浏览器缓存，通过设置http头中的Cache-Control 和 Expires 的属性，可以缓存js，css，logo，图标这种更新频率比较低的静态资源，并设置缓存天数。如果静态资源文件变化需要及时的应用到客户端浏览器的时候可以通过改变文件名来实现，即更新一个文件而不是更新文件的内容。 启用压缩，在服务器端对文件压缩，在浏览器对文件进行解压缩。可以对html，css，js文件启用GZip压缩可达到较好的效果。 CSS放在页面的最上面，JS放在页面最下面。css直接渲染，js会执行，如果时间长会阻塞整个页面，造成缓慢。 减少Cookie的传输。静态资源的访问，可以使用独立域名访问，避免请求静态资源时发送cookie。 CDN加速 反向代理，通过配置缓存的功能加速web请求。负载均衡，也可以热门信息缓存在反向代理服务器上，如果更新的话就通知缓存失效。 二、应用服务器性能优化，主要有缓存，集群，异步等。 分布式缓存，缓存可以存在浏览器，应用服务器和数据库服务器中。既可以对数据缓存，也可以对文件进行缓存，还可以对页面片段进行缓存。 缓存的基本原理，缓存就是将数据存储在相对较高访问速度的存储介质中 合理使用缓存，一般来说数据的读写比为2：1以上使用缓存才有意义。缓存系统启动时就把热点数据加载好，这个缓存预加载手段叫做缓存预热。缓存穿透，一个简单的对策是将不存在的数据也缓存起来。 分布式缓存架构。应用程序通过一致性hash等路由算法选择缓存服务器远程访问缓存数据，缓存服务器之间不通信。 Memcached，分布式服务器远程通信需要考虑两方面的要素，一个是通信协议，一个是通信序列化协议。 异步操作 加入消息队列，消息队列既能解耦，又能削峰。将短时间宝并发产生的事务消息存储在消息队列中，从而削平高峰期的并发事务。 使用集群 使用负载均衡技术为一个应用构建一个由多台服务器组成的服务器集群，将并发访问骑牛分发到多台服务器上处理。避免单一服务器因负载压力过大而相应缓慢。 代码优化 多线程处理，线程安全解决办法，1.将对象设计成无状态，这样在多线程并发访问的时候就不会出现状态不一致的情况，servlet对象的设计为无状态的对象。web开发中常用的贫血模型对象都是无状态对象，不过从面向对象的设计角度看的话，无状态对象是一种不良的设计。2.使用局部对象。3.加锁 资源复用。减少开销很大的系统资源的创建和销毁，比如数据库连接，网络通信连接，线程，复杂对象等。资源复用主要有两种模式：单例和对象池。 数据结构。一般的Hash算法是Time33算法，对字符串逐字符迭代乘以33，求得Hash值，hash(i) = hash(i-1) * 33 + str[i] 比如 AA 的 hashcode 是2210 AB的hashcode 是2211 。一个可行的方案是对字符串取信息指纹，再对信息求hashcode，原始字符串-&gt;MD5-&gt;hash计算 垃圾回收 三、存储性能优化 ​ B+树和LSM树：一般的NoSql产品采用LSM树作为主要的数据结构。LSM树可以看做是一个N阶合并树。 ​ RAID vs HDFS：HDFS以块为单位管理文件内容，一个文件被分割成若干个Block。每写完一个Block，HDFS就将其自动复制到另外两台机器上，保证每个Block有三个副本。当对文件进行处理计算时，通过MapReduce并发计算任务框架，启动多个计算子任务。]]></content>
      <categories>
        <category>架构相关</category>
      </categories>
      <tags>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生产者消费者]]></title>
    <url>%2F2018%2F04%2F22%2F%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%2F</url>
    <content type="text"><![CDATA[最近看了马士兵老师讲的并发课程，讲到这个例子的时候提出两个问题，现在自己经过反思消化，记录下来。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import java.util.LinkedList;import java.util.concurrent.TimeUnit;/** * Description:一个普通的生产者和消费者的例子 * @author xiudongxu * @date 2018/4/22 */public class ProducerAndConsumer &#123; final private LinkedList list = new LinkedList(); //存储容器 final private int MAX = 10; //元素最大个数 private int count = 0; public synchronized void put(Object obj)&#123; //问题1：这里为啥用while而不是if //假设有两个线程t1,t2在同时在wait处等待，而且容器此时突然有了一个空位置，而且已经被刚刚消费了的线程使用notifyall()唤醒了， //t1，t2接收到唤醒操作时，同时去获取对象锁，此时假设t2获取成功了。t2 添加一个元素，此时容器满了，t2线程使用notifyall唤醒t1线程。 //t1去获取对象锁，从this.wait()处继续执行代码。如果此时使用的是if 那么就出问题了，t1直接执行add操作，导致容器超出容量，报错。 //而如果是while循环的话，那么还会进行一次list.size() == MAX 判断。 //判断结束t1 又会wait 而释放锁。等待被唤醒添加元素。 //这样就不会出问题了。 //当然以上描述比较复杂，是因为要出现这种错误的话，需要天时地利人和， //但是这种极端的情况又必须要考虑好，才能保证万无一失。所以说这个经典问题是值得反复推敲的。 //而且《effective java》 中也说到 一般wait都要与while配合使用，如果不懂就记住。 while (list.size() == MAX)&#123; try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; list.add(obj); ++count; //问题2：为何用notifyall 而不是 notify //注：唤醒 是指线程的状态 从等待的状态变成就绪的状态。 //假设此时是有一个生产者线程，一个消费者线程在等待的状态。 //如果使用notify 唤醒的是一个生产者线程。那么就死锁等待了。所有的线程都是等待状态就死锁了。 //如果是notify 唤醒的是所有线程，即使是一个生产者线程，那么生产者线程等待失去锁的时候，消费者线程从就绪态获得锁会继续执行消费，而不是程序进入死锁的状态。 this.notifyAll(); &#125; public synchronized Object get()&#123; Object obj = null; while (list.size() == 0)&#123; try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; obj = list.removeFirst(); -- count; this.notifyAll(); return obj; &#125; public static void main(String[] args) &#123; ProducerAndConsumer pandc = new ProducerAndConsumer(); //启动消费者线程 for (int i = 0; i &lt; 10; i++) &#123; new Thread(()-&gt;&#123; for (int j = 0; j &lt; 5; j++) &#123; System.out.println(pandc.get()); &#125; &#125;,"consumer" + i).start(); &#125; //睡一会 try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //启动生产者线程 for (int i = 0; i &lt; 2; i++) &#123; new Thread(()-&gt;&#123; for (int j = 0; j &lt; 25; j++) &#123; pandc.put(Thread.currentThread().getName() + " " + j); &#125; &#125;,"producter" + i).start(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>JAVA学习</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Hexo搭建自己的博客]]></title>
    <url>%2F2018%2F03%2F31%2F%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[万事都有因想要搭建博客已经有很长时间了，虽然我觉得码字是件很麻烦的事情，但是很多前辈又说过，经常记录对自己的成长是有帮助的。所以万事开头难，一切慢慢练习，好好坚持。希望这是一个长期而且有意义的事情。 女票现在经常写点评，而且有的点评阅读量在几万以上，这么多阅读量我是很震惊的，她一般都是长文，字很多，图为并茂的那种，基本是每个菜品配图，配评论，然后总结一下服务、环境、价格、推荐指数等等。这样细致的点评也难怪经常被人点赞，经常被商家点赞。所以我要学习这种经常点评，总结的精神，就从现在开始吧。 因-&gt;果自从上一次搭建自己的博客是在17年的国庆假期，当时使用的是Jekyll,后来因为要调整的东西太多啦，就中途废止了。这次使用Hexo搭建了博客，感觉后者操作还是比较方便的，选用的主题也是自己比较中意的NexT。当然创建过程还算比较顺利的原因是得益于参考了很多先人的博客，多亏这个博客为我铺平道路，抱拳感谢~ 修改样式变得酷炫参考了这个博客，这位大神讲解的很细致，但是有几个点是不起效果的，而且因为我的版本是6.0.1 所以有些操作是不同的。 当然，经过仔细研究还是能解决的，毕竟也是研究代码的人，这个模板的套路摸清了就好搞啦~ 需要有点耐心奥。 搞了一晚上的样式，，有些已经实现，但是还有些不太完美，只能后续再进行了。 TODO List: 在线沟通 邀请码：0f81ff2f Travis CI 自动发布 参考链接：传送门 友情链接、图片文章 参考链接：传送门 附加今日发现的好玩的网站： easyicon ：一个图标网站。 JiaThis ：一个可以嵌入分享、评论、推荐按钮的功能的网站。 iissnan ：NexT作者的博客]]></content>
      <categories>
        <category>生活点滴</category>
      </categories>
      <tags>
        <tag>个人记录</tag>
      </tags>
  </entry>
</search>
